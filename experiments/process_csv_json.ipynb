{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minhd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from accelerate.hooks import AlignDevicesHook, add_hook_to_module\n",
    "import warnings\n",
    "from typing import Any, Dict, Optional, Tuple, Union\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutput,\n",
    "    Seq2SeqLMOutput,\n",
    ")\n",
    "from transformers.utils import (\n",
    "    logging,\n",
    "    replace_return_docstrings,\n",
    "    ModelOutput\n",
    ")\n",
    "from transformers.models.t5.modeling_t5 import __HEAD_MASK_WARNING_MSG\n",
    "import inspect\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "_CONFIG_FOR_DOC = \"T5Config\"\n",
    "from transformers import T5ForConditionalGeneration\n",
    "\n",
    "class FiD(T5ForConditionalGeneration):\n",
    "    @replace_return_docstrings(output_type=Seq2SeqLMOutput, config_class=_CONFIG_FOR_DOC)\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        decoder_input_ids: Optional[torch.LongTensor] = None,\n",
    "        decoder_attention_mask: Optional[torch.BoolTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        decoder_head_mask: Optional[torch.FloatTensor] = None,\n",
    "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
    "        encoder_outputs: Optional[Tuple[Tuple[torch.Tensor]]] = None,\n",
    "        past_key_values: Optional[Tuple[Tuple[torch.Tensor]]] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.FloatTensor], Seq2SeqLMOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[-100, 0, ...,\n",
    "            config.vocab_size - 1]`. All labels set to `-100` are ignored (masked), the loss is only computed for\n",
    "            labels in `[0, ..., config.vocab_size]`\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        Examples:\n",
    "\n",
    "        ```python\n",
    "        >>> from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "\n",
    "        >>> tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "        >>> model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "        >>> # training\n",
    "        >>> input_ids = tokenizer(\"The <extra_id_0> walks in <extra_id_1> park\", return_tensors=\"pt\").input_ids\n",
    "        >>> labels = tokenizer(\"<extra_id_0> cute dog <extra_id_1> the <extra_id_2>\", return_tensors=\"pt\").input_ids\n",
    "        >>> outputs = model(input_ids=input_ids, labels=labels)\n",
    "        >>> loss = outputs.loss\n",
    "        >>> logits = outputs.logits\n",
    "\n",
    "        >>> # inference\n",
    "        >>> input_ids = tokenizer(\n",
    "        ...     \"summarize: studies have shown that owning a dog is good for you\", return_tensors=\"pt\"\n",
    "        ... ).input_ids  # Batch size 1\n",
    "        >>> outputs = model.generate(input_ids)\n",
    "        >>> print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "        >>> # studies have shown that owning a dog is good for you.\n",
    "        ```\"\"\"\n",
    "        # print(\"attention_mask 1: \", attention_mask.size())\n",
    "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        # FutureWarning: head_mask was separated into two input args - head_mask, decoder_head_mask\n",
    "        if head_mask is not None and decoder_head_mask is None:\n",
    "            if self.config.num_layers == self.config.num_decoder_layers:\n",
    "                warnings.warn(__HEAD_MASK_WARNING_MSG, FutureWarning)\n",
    "                decoder_head_mask = head_mask\n",
    "\n",
    "        # NOTE: FiD\n",
    "        # Reshape from [batch, n_passages, length] to [batch * n_passages, length]\n",
    "        if input_ids is not None:\n",
    "            if input_ids.dim() == 3 and attention_mask.dim() == 3:\n",
    "                #logger.info(\"Start Reshape from [batch, n_passage, length] to [batch * n_passage, length]\")\n",
    "                self.n_passages = input_ids.size(1)\n",
    "                self.batch = input_ids.size(0)\n",
    "                self.seq_length = input_ids.size(2)\n",
    "                input_ids = input_ids.view(self.batch*self.n_passages, self.seq_length)\n",
    "                attention_mask = attention_mask.view(self.batch*self.n_passages, self.seq_length)\n",
    "            else:\n",
    "                raise ValueError(f\"NOT FiD TRAINING, got input_ids {input_ids.size()} and attention_mask {attention_mask.size()}\")\n",
    "\n",
    "        # Encode if needed (training, first prediction pass)\n",
    "        if encoder_outputs is None:\n",
    "            # Convert encoder inputs in embeddings if needed\n",
    "            # print(\"attention_mask 2: \", attention_mask.size())\n",
    "            # print(f\"batchsize: {self.batch}, n_passages: {self.n_passages}, seq_length: {self.seq_length}\")\n",
    "            encoder_outputs = self.encoder(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                inputs_embeds=inputs_embeds,\n",
    "                head_mask=head_mask,\n",
    "                output_attentions=output_attentions,\n",
    "                output_hidden_states=output_hidden_states,\n",
    "                return_dict=return_dict,\n",
    "            )\n",
    "        elif return_dict and not isinstance(encoder_outputs, BaseModelOutput):\n",
    "            encoder_outputs = BaseModelOutput(\n",
    "                last_hidden_state=encoder_outputs[0],\n",
    "                hidden_states=encoder_outputs[1] if len(encoder_outputs) > 1 else None,\n",
    "                attentions=encoder_outputs[2] if len(encoder_outputs) > 2 else None,\n",
    "            )\n",
    "\n",
    "        # [batch*n_passages, seq_length, model_dim]\n",
    "        hidden_states = encoder_outputs[0]\n",
    "\n",
    "        # NOTE: FiD\n",
    "        # from [batch*n_passages, seq_length, model_dim] to [batch, n_passages*seq_length, model_dim]\n",
    "        hidden_states = hidden_states.view(self.batch, self.n_passages*self.seq_length, -1)\n",
    "\n",
    "        if self.model_parallel:\n",
    "            torch.cuda.set_device(self.decoder.first_device)\n",
    "\n",
    "        if labels is not None and decoder_input_ids is None and decoder_inputs_embeds is None:\n",
    "            # get decoder inputs from shifting lm labels to the right\n",
    "            decoder_input_ids = self._shift_right(labels)\n",
    "\n",
    "        # Set device for model parallelism\n",
    "        if self.model_parallel:\n",
    "            torch.cuda.set_device(self.decoder.first_device)\n",
    "            hidden_states = hidden_states.to(self.decoder.first_device)\n",
    "            if decoder_input_ids is not None:\n",
    "                decoder_input_ids = decoder_input_ids.to(self.decoder.first_device)\n",
    "            if attention_mask is not None:\n",
    "                attention_mask = attention_mask.to(self.decoder.first_device)\n",
    "            if decoder_attention_mask is not None:\n",
    "                decoder_attention_mask = decoder_attention_mask.to(self.decoder.first_device)\n",
    "\n",
    "        # NOTE: change(FiD): reshape attention mask\n",
    "        # print(\"attention_mask 3: \", attention_mask.size())\n",
    "        # print(f\"batchsize: {self.batch}, n_passages: {self.n_passages}, seq_length: {self.seq_length}\")\n",
    "        attention_mask = attention_mask.view(-1, self.n_passages*self.seq_length)\n",
    "        # Decode\n",
    "        decoder_outputs = self.decoder(\n",
    "            input_ids=decoder_input_ids,\n",
    "            attention_mask=decoder_attention_mask,\n",
    "            inputs_embeds=decoder_inputs_embeds,\n",
    "            past_key_values=past_key_values,\n",
    "            encoder_hidden_states=hidden_states,\n",
    "            encoder_attention_mask=attention_mask,\n",
    "            head_mask=decoder_head_mask,\n",
    "            cross_attn_head_mask=cross_attn_head_mask,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = decoder_outputs[0]\n",
    "\n",
    "        # Set device for model parallelism\n",
    "        if self.model_parallel:\n",
    "            torch.cuda.set_device(self.encoder.first_device)\n",
    "            self.lm_head = self.lm_head.to(self.encoder.first_device)\n",
    "            sequence_output = sequence_output.to(self.lm_head.weight.device)\n",
    "\n",
    "        if self.config.tie_word_embeddings:\n",
    "            # Rescale output before projecting on vocab\n",
    "            # See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/transformer/transformer.py#L586\n",
    "            sequence_output = sequence_output * (self.model_dim**-0.5)\n",
    "\n",
    "        lm_logits = self.lm_head(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss(ignore_index=-100)\n",
    "            # move labels to correct device to enable PP\n",
    "            labels = labels.to(lm_logits.device)\n",
    "            loss = loss_fct(lm_logits.view(-1, lm_logits.size(-1)), labels.view(-1))\n",
    "            # TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (lm_logits,) + decoder_outputs[1:] + encoder_outputs\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return Seq2SeqLMOutput(\n",
    "            loss=loss,\n",
    "            logits=lm_logits,\n",
    "            past_key_values=decoder_outputs.past_key_values,\n",
    "            decoder_hidden_states=decoder_outputs.hidden_states,\n",
    "            decoder_attentions=decoder_outputs.attentions,\n",
    "            cross_attentions=decoder_outputs.cross_attentions,\n",
    "            encoder_last_hidden_state=encoder_outputs.last_hidden_state,\n",
    "            encoder_hidden_states=encoder_outputs.hidden_states,\n",
    "            encoder_attentions=encoder_outputs.attentions,\n",
    "        )\n",
    "\n",
    "    def _prepare_encoder_decoder_kwargs_for_generation(\n",
    "        self, inputs_tensor: torch.Tensor, model_kwargs, model_input_name: Optional[str] = None\n",
    "    ) -> Dict[str, Any]:\n",
    "        # print(\"attention_mask 4: \", model_kwargs[\"attention_mask\"].size())\n",
    "        if inputs_tensor.dim() == 3:\n",
    "            #logger.info(\"Start Reshape from [batch, n_passage, length] to [batch * n_passage, length]\")\n",
    "            self.n_passages = inputs_tensor.size(1)\n",
    "            self.batch = inputs_tensor.size(0)\n",
    "            self.seq_length = inputs_tensor.size(2)\n",
    "            inputs_tensor = inputs_tensor.view(self.batch*self.n_passages, self.seq_length)\n",
    "            model_kwargs[\"attention_mask\"] = model_kwargs[\"attention_mask\"].view(self.batch*self.n_passages, self.seq_length)\n",
    "            # print(\"attention_mask 5: \", model_kwargs[\"attention_mask\"].size())\n",
    "            # print(f\"batchsize: {self.batch}, n_passages: {self.n_passages}, seq_length: {self.seq_length}\")\n",
    "\n",
    "        # 1. get encoder\n",
    "        encoder = self.get_encoder()\n",
    "        # Compatibility with Accelerate big model inference: we need the encoder to outputs stuff on the same device\n",
    "        # as the inputs.\n",
    "        if hasattr(self, \"hf_device_map\"):\n",
    "            if hasattr(encoder, \"_hf_hook\"):\n",
    "                encoder._hf_hook.io_same_device = True\n",
    "            else:\n",
    "                add_hook_to_module(encoder, AlignDevicesHook(io_same_device=True))\n",
    "\n",
    "        # 2. Prepare encoder args and encoder kwargs from model kwargs.\n",
    "        irrelevant_prefix = [\"decoder_\", \"cross_attn\", \"use_cache\"]\n",
    "        encoder_kwargs = {\n",
    "            argument: value\n",
    "            for argument, value in model_kwargs.items()\n",
    "            if not any(argument.startswith(p) for p in irrelevant_prefix)\n",
    "        }\n",
    "        encoder_signature = set(inspect.signature(encoder.forward).parameters)\n",
    "        encoder_accepts_wildcard = \"kwargs\" in encoder_signature or \"model_kwargs\" in encoder_signature\n",
    "        if not encoder_accepts_wildcard:\n",
    "            encoder_kwargs = {\n",
    "                argument: value for argument, value in encoder_kwargs.items() if argument in encoder_signature\n",
    "            }\n",
    "\n",
    "        # 3. make sure that encoder returns `ModelOutput`\n",
    "        model_input_name = model_input_name if model_input_name is not None else self.main_input_name\n",
    "\n",
    "        encoder_kwargs[\"return_dict\"] = True\n",
    "        encoder_kwargs[model_input_name] = inputs_tensor\n",
    "        encoder_outputs = encoder(**encoder_kwargs)\n",
    "        # print(\"encoder_outputs: \", encoder_outputs)\n",
    "        encoder_outputs[\"last_hidden_state\"] = encoder_outputs[\"last_hidden_state\"].view(self.batch, self.n_passages*self.seq_length, -1)\n",
    "        model_kwargs[\"encoder_outputs\"]: ModelOutput = encoder_outputs\n",
    "        # model_kwargs[\"attention_mask\"] = model_kwargs[\"attention_mask\"].view(self.batch, self.n_passages*self.seq_length)\n",
    "\n",
    "        return model_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import BaseComponent\n",
    "from transformers import AutoTokenizer\n",
    "from typing import List, Optional\n",
    "\n",
    "class FiDReader(BaseComponent):\n",
    "    outgoing_edges = 1\n",
    "\n",
    "    def __init__(self, \n",
    "                 model_name_or_path: str = \"gradients-ai/fid_large_en_v1.0\",\n",
    "                 device: str = \"cpu\"):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        print(\"Initializing model...\")\n",
    "        self.model = FiD.from_pretrained(model_name_or_path)\n",
    "        self.model.to(self.device)\n",
    "        print(\"Done!\")\n",
    "        print(\"Initializing tokenizer...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "        print(\"Done!\")\n",
    "\n",
    "    def append_question(\n",
    "            self,\n",
    "            question: str,\n",
    "            documents: List[str],\n",
    "            question_prefix: str = \"Question: \",\n",
    "            document_prefix: str = \"Document: \"\n",
    "    ) -> List[str]:\n",
    "        \"\"\"Pair question to each document\n",
    "\n",
    "        Args:\n",
    "            question:\n",
    "                a string - question\n",
    "            documents:\n",
    "                a list of string\n",
    "        Returns:\n",
    "            A question is paired with each document in `documents`\n",
    "            become a list of string\n",
    "        \"\"\"\n",
    "\n",
    "        if documents is None:\n",
    "            return [question_prefix + question]\n",
    "        return [question_prefix + question + \" \" + document_prefix + d for d in documents] \n",
    "\n",
    "    def run(self, query, documents):\n",
    "        # pprint(contexts)\n",
    "        # print(\"Contexts len:\", len(contexts))\n",
    "        # print(top2_docs)\n",
    "        inputs = self.append_question(\n",
    "            query,\n",
    "            list(doc.content for doc in documents)\n",
    "        )\n",
    "        tokenized_input = self.tokenizer(inputs, return_tensors=\"pt\", padding=True)\n",
    "        input_tensor = tokenized_input.input_ids[None, :, :].to(self.device)\n",
    "        attention_mask = tokenized_input.attention_mask[None, :, :].to(self.device)\n",
    "        print(\"Generating answers...\")\n",
    "        model_outputs = self.model.generate(\n",
    "            input_ids=input_tensor,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=256,\n",
    "            min_length=64,\n",
    "            do_sample=True,\n",
    "            num_beams=1,\n",
    "            top_k=50,\n",
    "            top_p=0.9,\n",
    "            temperature=0.7,\n",
    "            num_return_sequences=1,\n",
    "            no_repeat_ngram_size=3,\n",
    "            repetition_penalty=1.1\n",
    "        )\n",
    "        output = {\"answer\": []}\n",
    "        print(\"Model output len:\", len(model_outputs))\n",
    "        for out in model_outputs:\n",
    "            output[\"answer\"].append(\n",
    "                self.tokenizer.decode(out, skip_special_tokens=True)\n",
    "            )\n",
    "        return output, \"output_1\"\n",
    "    \n",
    "    def run_batch(self, queries: List[str], my_optional_param: Optional[int]):\n",
    "        # process the inputs\n",
    "        output = {\"my_output\": ...}\n",
    "        return output, \"output_1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is a novel coronavirus?</td>\n",
       "      <td>A novel coronavirus is a new coronavirus that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is the disease being called coronavirus di...</td>\n",
       "      <td>On February 11, 2020 the World Health Organiza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why might someone blame or avoid individuals a...</td>\n",
       "      <td>People in the U.S. may be worried or anxious a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can people help stop stigma related to COV...</td>\n",
       "      <td>People can fight stigma and help, not hurt, ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the source of the virus?</td>\n",
       "      <td>Coronaviruses are a large family of viruses. S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                       What is a novel coronavirus?   \n",
       "1  Why is the disease being called coronavirus di...   \n",
       "2  Why might someone blame or avoid individuals a...   \n",
       "3  How can people help stop stigma related to COV...   \n",
       "4                   What is the source of the virus?   \n",
       "\n",
       "                                             content  \n",
       "0  A novel coronavirus is a new coronavirus that ...  \n",
       "1  On February 11, 2020 the World Health Organiza...  \n",
       "2  People in the U.S. may be worried or anxious a...  \n",
       "3  People can fight stigma and help, not hurt, ot...  \n",
       "4  Coronaviruses are a large family of viruses. S...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"faq.csv\", index_col=0)\n",
    "df.columns = ['title', 'content']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Why might someone blame or avoid individuals a...</td>\n",
       "      <td>People in the U.S. may be worried or anxious a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "count                                                 213   \n",
       "unique                                                210   \n",
       "top     Why might someone blame or avoid individuals a...   \n",
       "freq                                                    2   \n",
       "\n",
       "                                                  content  \n",
       "count                                                 213  \n",
       "unique                                                210  \n",
       "top     People in the U.S. may be worried or anxious a...  \n",
       "freq                                                    2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_stores.faiss import FAISSDocumentStore\n",
    "from haystack.nodes import EmbeddingRetriever\n",
    "from haystack.nodes import PreProcessor\n",
    "from haystack.schema import Document\n",
    "from haystack.pipelines import Pipeline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"faiss_document_store.db\"):\n",
    "    os.remove(\"faiss_document_store.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minhd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n",
      "Done!\n",
      "Initializing tokenizer...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "retriever = EmbeddingRetriever(\"BAAI/bge-large-en-v1.5\", use_gpu=True)\n",
    "document_store = FAISSDocumentStore(\n",
    "    faiss_index_factory_str=\"Flat\",\n",
    "    embedding_dim=1024,\n",
    "    return_embedding=True\n",
    ")\n",
    "reader = FiDReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.0510522 ,  0.00719567,  0.00387395, ..., -0.0314708 ,\n",
       "       -0.0355579 , -0.01076885], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.embedding_encoder.embed(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.75it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 38.81it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.04it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 28.28it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 27.59it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.75it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 48.53it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 42.03it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 47.37it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.24it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 48.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.92it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.75it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 48.10it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.34it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.79it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.26it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.41it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.42it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 39.87it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 48.23it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.89it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.25it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.79it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.22it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 48.69it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.19it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 34.25it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.79it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.91it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 48.54it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.81it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.09it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.88it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.91it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.98it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 36.70it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.93it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.38it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 42.41it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.01it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.84it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 35.58it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.75it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.39it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.53it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.38it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 48.60it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.77it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.44it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.33it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.04it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 56.67it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.54it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 35.64it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.71it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 42.00it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.35it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.00it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 42.94it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.82it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 38.88it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 44.33it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 31.09it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 46.23it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 44.79it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 38.99it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 42.87it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 40.36it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 35.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 47.74it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 44.75it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.12it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.86it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.67it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 47.47it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.91it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.90it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.12it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.89it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.92it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.92it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.16it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.29it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 38.43it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 39.14it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 38.88it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 38.43it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 29.15it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.51it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 31.93it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 39.63it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.44it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.58it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 40.34it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.96it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.42it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 44.18it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 46.12it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 38.31it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 30.24it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.82it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.22it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 37.35it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 35.35it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 48.45it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.15it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 37.97it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.30it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 47.53it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.02it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.29it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 47.54it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.84it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 56.79it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.01it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.34it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.46it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.38it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 47.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.79it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 47.52it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 32.43it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.22it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.20it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 46.36it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 42.43it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 29.66it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 37.64it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.40it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.54it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.88it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 47.53it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.51it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.20it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.37it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.08it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 34.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 33.38it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.25it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.53it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.92it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.09it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.51it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.89it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.41it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.79it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.54it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 56.54it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 32.95it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.25it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.78it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.49it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.88it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.88it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.50it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.75it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.59it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.46it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.91it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.90it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 44.25it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.85it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 39.03it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 47.53it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.62it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 42.36it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 47.51it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 36.29it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 37.41it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 29.32it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 44.31it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 46.43it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 42.43it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.91it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.80it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 44.47it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 38.81it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.71it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.64it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 32.19it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.21it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.57it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.78it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 34.09it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 40.59it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.55it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.38it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 33.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 46.83it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.99it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.58it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 46.31it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 47.53it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 48.66it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.18it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.35it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.70it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.10it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 37.50it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.16it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 44.81it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.50it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 56.40it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.41it/s]\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    title = row['title']\n",
    "    content = row['content']\n",
    "    embedding = retriever.embedding_encoder.embed(title)\n",
    "    doc = Document(\n",
    "        content=content,\n",
    "        embedding=embedding\n",
    "    )\n",
    "    documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing Documents: 10000it [00:00, 32557.62it/s]          \n"
     ]
    }
   ],
   "source": [
    "document_store.write_documents(documents=documents)\n",
    "retriever.document_store = document_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline()\n",
    "pipeline.add_node(component=retriever, name=\"retriever\", inputs=[\"Query\"])\n",
    "pipeline.add_node(component=reader, name=\"reader\", inputs=[\"retriever\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.61it/s]\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Covid?\"\n",
    "\n",
    "outputs = retriever.retrieve(query, top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COVID-19 is the infectious disease caused by the most recently discovered coronavirus. This new virus and disease were unknown before the outbreak began in Wuhan, China, in December 2019.\n",
      "0.5022707453715565\n",
      "Severe Acute Respiratory Syndrome Coronavirus-2 (SARS-CoV-2) is the name given to the 2019 novel coronavirus. COVID-19 is the name given to the disease associated with the virus. SARS-CoV-2 is a new strain of coronavirus that has not been previously identified in humans.\n",
      "0.5021145941903251\n",
      "Coronaviruses are a large family of viruses which may cause illness in animals or humans.  In humans, several coronaviruses are known to cause respiratory infections ranging from the common cold to more severe diseases such as Middle East Respiratory Syndrome (MERS) and Severe Acute Respiratory Syndrome (SARS). The most recently discovered coronavirus causes coronavirus disease COVID-19.\n",
      "0.5020081152828929\n",
      "Coronaviruses are a large group of viruses that are common among animals and humans. This novel coronavirus that causes COVID-19 is a newly discovered coronavirus that has not been previously detected in animals or humans. The source of this virus is not yet known.\n",
      "\n",
      "0.501971279748725\n",
      "Typically, human coronaviruses cause mild-to-moderate respiratory illness. Symptoms are very similar to the flu, including:\n",
      "\n",
      "Fever\n",
      "Cough\n",
      "Shortness of breath\n",
      "COVID-19 can cause more severe respiratory illness.\n",
      "0.5019162659401245\n",
      "The most common symptoms of COVID-19 are fever, tiredness, and dry cough. Some patients may have aches and pains, nasal congestion, runny nose, sore throat or diarrhea. These symptoms are usually mild and begin gradually. Some people become infected but don’t develop any symptoms and don't feel unwell. Most people (about 80%) recover from the disease without needing special treatment. Around 1 out of every 6 people who gets COVID-19 becomes seriously ill and develops difficulty breathing. Older people, and those with underlying medical problems like high blood pressure, heart problems or diabetes, are more likely to develop serious illness. People with fever, cough and difficulty breathing should seek medical attention.\n",
      "0.5019162659401245\n",
      "The European Centre for Disease Prevention and Control (ECDC) is in continuous contact with the European Commission and the World Health Organization regarding the assessment of this outbreak. To inform the European Commission and the public health authorities in Member States of the ongoing situation, ECDC publishes daily summaries and continuously assesses the risk for EU citizens. ECDC and WHO have developed technical guidance to support the EU Member States in their response. The European Commission is ensuring the coordination of risk management activities at EU level.\n",
      "0.5019118862550106\n",
      "Current symptoms reported for patients with COVID-19 have included mild to severe respiratory illness with fever, cough, and difficulty breathing. Read about COVID-19 Symptoms.\n",
      "0.5019044238621704\n",
      "From the international data we have, of those who have tested positive for COVID-19, approximately 80 percent do not exhibit symptoms that would require hospitalization. For patients who are more severely ill, hospitals can provide supportive care. We are continuing to learn more about this novel coronavirus and treatment may change over time. \n",
      "0.5018957398888593\n",
      "This is an emerging, rapidly evolving situation and CDC will continue to provide updated information as it becomes available. CDC works 24/7 to protect people’s health. More information about CDC’s response to COVID-19 is available online.\n",
      "0.5018918383737949\n"
     ]
    }
   ],
   "source": [
    "for output in outputs:\n",
    "    print(output.content)\n",
    "    print(output.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 23.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating answers...\n",
      "Model output len: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': [\"You have a cold, it's like the flu. Your body produces antibodies to fight off the virus, but they don't last for long. In fact, the virus can survive for days on end without your body producing any antibodies at all. It's kind of like how you get pneumonia from the flu: the virus will survive for weeks on end before your body starts producing antibodies.\"],\n",
       " 'documents': [<Document: {'content': 'Typically, human coronaviruses cause mild-to-moderate respiratory illness. Symptoms are very similar to the flu, including:\\r\\n\\r\\nFever\\r\\nCough\\r\\nShortness of breath\\r\\nCOVID-19 can cause more severe respiratory illness.', 'content_type': 'text', 'score': 0.5022833933638616, 'meta': {'vector_id': '141'}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (1024,)>', 'id': 'c61b47cdc2a36a0e4c418499a2f33b8e'}>,\n",
       "  <Document: {'content': \"The most common symptoms of COVID-19 are fever, tiredness, and dry cough. Some patients may have aches and pains, nasal congestion, runny nose, sore throat or diarrhea. These symptoms are usually mild and begin gradually. Some people become infected but don’t develop any symptoms and don't feel unwell. Most people (about 80%) recover from the disease without needing special treatment. Around 1 out of every 6 people who gets COVID-19 becomes seriously ill and develops difficulty breathing. Older people, and those with underlying medical problems like high blood pressure, heart problems or diabetes, are more likely to develop serious illness. People with fever, cough and difficulty breathing should seek medical attention.\", 'content_type': 'text', 'score': 0.5022833933638616, 'meta': {'vector_id': '113'}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (1024,)>', 'id': '37fd5fa341c1b2438cb706c3c2b5a3b6'}>,\n",
       "  <Document: {'content': 'The virus can cause mild, flu-like symptoms such as:\\r\\n\\r\\nfever\\r\\ncough\\r\\ndifficulty breathing\\r\\nmuscle pain\\r\\ntiredness\\r\\nMore serious cases develop severe pneumonia, acute respiratory distress syndrome, sepsis and septic shock that can lead to death. ', 'content_type': 'text', 'score': 0.5020936867413267, 'meta': {'vector_id': '158'}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (1024,)>', 'id': 'a6d0ccf45d71c6e96113b6bd6d85cd08'}>,\n",
       "  <Document: {'content': 'Current symptoms reported for patients with COVID-19 have included mild to severe respiratory illness with fever, cough, and difficulty breathing. Read about COVID-19 Symptoms.', 'content_type': 'text', 'score': 0.5020482827880902, 'meta': {'vector_id': '19'}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (1024,)>', 'id': '73651fbde086a929c9434330a1fa0929'}>,\n",
       "  <Document: {'content': '\\r\\nThe clinical spectrum of COVID-19 ranges from mild disease with non-specific signs and symptoms of acute respiratory illness, to severe pneumonia with respiratory failure and septic shock. There have also been reports of asymptomatic infection with COVID-19. See also Interim Clinical Guidance for Management of Patients with Confirmed Coronavirus Disease 2019 (COVID-19).', 'content_type': 'text', 'score': 0.5019987777691607, 'meta': {'vector_id': '73'}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (1024,)>', 'id': '5ca901d00285d9c946812f281ae16dc'}>,\n",
       "  <Document: {'content': 'COVID-19 is the infectious disease caused by the most recently discovered coronavirus. This new virus and disease were unknown before the outbreak began in Wuhan, China, in December 2019.', 'content_type': 'text', 'score': 0.5019340293510394, 'meta': {'vector_id': '112'}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (1024,)>', 'id': '922329a3631ab857428e552612ece02f'}>,\n",
       "  <Document: {'content': 'You should establish procedures to ensure students and staff who become sick at school or who arrive at school sick are sent home as soon as possible. Keep sick students and staff separate from well students and staff until sick students and staff can be sent home.', 'content_type': 'text', 'score': 0.5018863679375881, 'meta': {'vector_id': '99'}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (1024,)>', 'id': '6ec8dee76540a0804251ea52191b02f'}>,\n",
       "  <Document: {'content': 'No. The symptoms of COVID-19 are similar in children and adults. However, children with confirmed COVID-19 have generally presented with mild symptoms. Reported symptoms in children include cold-like symptoms, such as fever, runny nose, and cough. Vomiting and diarrhea have also been reported. It’s not known yet whether some children may be at higher risk for severe illness, for example, children with underlying medical conditions and special healthcare needs. There is much more to be learned about how the disease impacts children.', 'content_type': 'text', 'score': 0.5018838580216747, 'meta': {'vector_id': '61'}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (1024,)>', 'id': '7e57a422573ac01b399a8317f40f39cc'}>,\n",
       "  <Document: {'content': 'Most people who get COVID-19 will be able to recover at home. CDC has directions for people who are recovering at home and their caregivers, including:\\r\\n\\r\\nStay home when you are sick, except to get medical care.\\r\\nIf you develop emergency warning signs for COVID-19 get medical attention immediately. In adults, emergency warning signs*:\\r\\nDifficulty breathing or shortness of breath\\r\\nPersistent pain or pressure in the chest\\r\\nNew confusion or inability to arouse\\r\\nBluish lips or face\\r\\n*This list is not all inclusive. Please consult your medical provider for any other symptom that is severe or concerning.\\r\\nUse a separate room and bathroom for sick household members (if possible).\\r\\nClean hands regularly by handwashing with soap and water or using an alcohol-based hand sanitizer with at least 60% alcohol.\\r\\nProvide your sick household member with clean disposable facemasks to wear at home, if available, to help prevent spreading COVID-19 to others.\\r\\nClean the sick room and bathroom, as needed, to avoid unnecessary contact with the sick person.\\r\\nAvoid sharing personal items like utensils, food, and drinks.', 'content_type': 'text', 'score': 0.5018496834299255, 'meta': {'vector_id': '49'}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (1024,)>', 'id': 'ea43e982df1658ecd901c1d016d3aaa2'}>,\n",
       "  <Document: {'content': 'Persons who have had personal contact with someone confirmed as carrying SARS-CoV-2 should immediately, and irrespective of symptoms, contact their competent health office, get in touch with the doctor or call 116117 – and stay at home.\\r\\n\\r\\nA coronavirus infection causes flu-like symptoms such as dry cough, fever, a runny nose and fatigue. There have also been reports of difficulties breathing, an itchy throat, headaches, joint pains, nausea, diarrhoea and shivering.', 'content_type': 'text', 'score': 0.5018452345999777, 'meta': {'vector_id': '184'}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (1024,)>', 'id': 'ce5105c5bc613bb3b6fa87a78a59e29a'}>],\n",
       " 'root_node': 'Query',\n",
       " 'params': {},\n",
       " 'query': 'What is the symptoms of Covid?',\n",
       " 'node_id': 'reader'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the symptoms of Covid?\"\n",
    "\n",
    "answer = pipeline.run(query=query)\n",
    "\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have a cold, it's like the flu. Your body produces antibodies to fight off the virus, but they don't last for long. In fact, the virus can survive for days on end without your body producing any antibodies at all. It's kind of like how you get pneumonia from the flu: the virus will survive for weeks on end before your body starts producing antibodies.\n"
     ]
    }
   ],
   "source": [
    "print(answer['answer'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
