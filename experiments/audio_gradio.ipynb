{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minhd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import (\n",
    "    Wav2Vec2ConformerForCTC, \n",
    "    Wav2Vec2Processor, \n",
    "    pipeline\n",
    ")\n",
    "import torch\n",
    "import librosa\n",
    "import sounddevice as sd\n",
    "import warnings\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        s2t_model_name_or_path: str = \"facebook/wav2vec2-conformer-rel-pos-large-960h-ft\",\n",
    "        t2s_model_name_or_path: str = \"suno/bark-small\",\n",
    "        s2t_is_gpu: bool = False,\n",
    "        t2s_is_gpu: bool = False    \n",
    "    ) -> None:\n",
    "        self.s2t_device = 'cuda' if s2t_is_gpu else \"cpu\"\n",
    "        self.t2s_device = 'cuda' if t2s_is_gpu else \"cpu\"\n",
    "        self.s2t_processor = Wav2Vec2Processor.from_pretrained(s2t_model_name_or_path)\n",
    "        self.s2t_model = Wav2Vec2ConformerForCTC.from_pretrained(s2t_model_name_or_path).to(self.s2t_device)\n",
    "        self.t2s_model = pipeline(\"text-to-speech\", t2s_model_name_or_path, device=self.t2s_device)\n",
    "\n",
    "    def s2t_transcribe(\n",
    "        self, \n",
    "        audio_input: tuple\n",
    "    ) -> str:\n",
    "        sr, audio = audio_input\n",
    "        audio = audio.astype(np.float32)\n",
    "        audio /= np.max(np.abs(audio))\n",
    "\n",
    "        if sr != 16000:\n",
    "            audio = librosa.resample(audio, orig_sr=sr, target_sr=16000)\n",
    "        input_values = self.s2t_processor(audio, sampling_rate=16000, return_tensors=\"pt\").input_values\n",
    "        logits = self.s2t_model(input_values.to(self.s2t_device)).logits\n",
    "        pred_ids = torch.argmax(logits, dim=-1)\n",
    "        pred_transcript = self.s2t_processor.batch_decode(pred_ids)[0]\n",
    "        print(pred_transcript)\n",
    "        return pred_transcript \n",
    "    \n",
    "    def t2s_transcribe(\n",
    "        self, \n",
    "        text: str\n",
    "    ) -> None:\n",
    "        speech =  self.t2s_model(text, forward_params={\"do_sample\": True})\n",
    "        print(\"Speaking...\")\n",
    "        sd.play(speech[\"audio\"][0], speech['sampling_rate'])\n",
    "        sd.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-conformer-rel-pos-large-960h-ft were not used when initializing Wav2Vec2ConformerForCTC: ['wav2vec2_conformer.encoder.pos_conv_embed.conv.weight_v', 'wav2vec2_conformer.encoder.pos_conv_embed.conv.weight_g']\n",
      "- This IS expected if you are initializing Wav2Vec2ConformerForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ConformerForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ConformerForCTC were not initialized from the model checkpoint at facebook/wav2vec2-conformer-rel-pos-large-960h-ft and are newly initialized: ['wav2vec2_conformer.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2_conformer.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\minhd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\utils\\weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HENO HANO HENO HELO HELO\n",
      "Speaking...\n"
     ]
    }
   ],
   "source": [
    "def s2t(audio):\n",
    "    global model\n",
    "    # print(audio)\n",
    "    text = model.s2t_transcribe(audio)\n",
    "    return text\n",
    "\n",
    "def t2s(text):\n",
    "    global model\n",
    "    model.t2s_transcribe(text)\n",
    "    \n",
    "model = AudioModel()\n",
    "with gr.Blocks() as demo:\n",
    "    audio = gr.Audio(source='microphone', type='numpy')\n",
    "    text = gr.Text(interactive=False)\n",
    "    audio.stop_recording(s2t, audio, text).then(t2s, text, None)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minhd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minhd\\AppData\\Local\\Temp\\gradio\\37ba341e1e3abb1d48c9755cca23fc85ce6c5dc1\\en_test.wav\n",
      "[[None, ('C:\\\\Users\\\\minhd\\\\AppData\\\\Local\\\\Temp\\\\gradio\\\\5a683f8a6f45f11742a0c046be5e9bb163010192\\\\Recording.mp3',)], (None, ('C:\\\\Users\\\\minhd\\\\AppData\\\\Local\\\\Temp\\\\gradio\\\\37ba341e1e3abb1d48c9755cca23fc85ce6c5dc1\\\\en_test.wav',))]\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Chatbot demo with multimodal input (text, markdown, LaTeX, code blocks, image, audio, & video). Plus shows support for streaming text.\n",
    "\n",
    "\n",
    "def add_text(history, text):\n",
    "    history = history + [(text, None)]\n",
    "    return history, gr.Textbox(value=\"\", interactive=False)\n",
    "\n",
    "\n",
    "def add_file(history, file):\n",
    "    print(file.name)\n",
    "    history = history + [(None, (file.name,))]\n",
    "    print(history)\n",
    "    return history\n",
    "\n",
    "\n",
    "def bot(history):\n",
    "    response = \"**That's cool!**\"\n",
    "    history[-1][1] = \"\"\n",
    "    for character in response:\n",
    "        history[-1][1] += character\n",
    "        time.sleep(0.05)\n",
    "        yield history\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(\n",
    "        [(None, (r\"C:\\Users\\minhd\\AppData\\Local\\Temp\\gradio\\5a683f8a6f45f11742a0c046be5e9bb163010192\\Recording.mp3\",))],\n",
    "        elem_id=\"chatbot\",\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        txt = gr.Textbox(\n",
    "            scale=4,\n",
    "            show_label=False,\n",
    "            placeholder=\"Enter text and press enter, or upload an image\",\n",
    "            container=False,\n",
    "        )\n",
    "        btn = gr.UploadButton(\"üìÅ\", file_types=[\"file\"])\n",
    "\n",
    "    txt_msg = txt.submit(add_text, [chatbot, txt], [chatbot, txt], queue=False).then(\n",
    "        bot, chatbot, chatbot, api_name=\"bot_response\"\n",
    "    )\n",
    "    txt_msg.then(lambda: gr.Textbox(interactive=True), None, [txt], queue=False)\n",
    "    file_msg = btn.upload(add_file, [chatbot, btn], [chatbot], queue=False)\n",
    "    gr.update(\"chatbot\")\n",
    "\n",
    "demo.queue()\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(allowed_paths=[\"avatar.png\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minhd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Chatbot([\n",
    "        (\"Show me an image and an audio file\", \"Here is an image\"), \n",
    "        (None, (\"dog.jpg\",)), \n",
    "        (None, \"And here is an audio file:\"), \n",
    "        ((r\"C:\\Users\\minhd\\AppData\\Local\\Temp\\gradio\\0da9d8e97a4c1ac5dea616b6c960ae5e46950c98\\input.wav\",), None)\n",
    "    ])#.style(height=1000)\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
